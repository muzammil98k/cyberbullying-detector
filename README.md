# AI-Augmented System for Identifying Online Harassment and Cyberbullying

## ğŸ’¡ Project Overview
This project aims to build an AI system capable of detecting toxic, hateful, or offensive language in user-generated content. It focuses on identifying different forms of online harassment using NLP and machine learning models.

## ğŸ“‚ Dataset
We are using the [Jigsaw Toxic Comment Classification Dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge). The dataset contains Wikipedia comments labeled for multiple types of toxicity.

## ğŸ§  Technologies Used
- Python
- Scikit-learn
- NLTK
- Pandas / NumPy
- Matplotlib / Seaborn
- (Optional) Transformers (BERT), Keras, Gradio

## ğŸ—ï¸ Project Structure
cyberbullying-detector/
â”œâ”€â”€ data/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ models/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ predict.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ app.py

## âœ… Goals
- Preprocess and analyze text data
- Train classification models
- Build a simple UI to detect cyberbullying
- Evaluate and explain model predictions

## ğŸ“Œ Status
Day 1 complete: Project setup, dataset selected, and initial files created.
